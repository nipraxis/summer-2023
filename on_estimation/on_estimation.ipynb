{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179905a9",
   "metadata": {},
   "source": [
    "# Some mathematics on least-squares regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a831ec0",
   "metadata": {},
   "source": [
    "## Introduction and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Import numerical and plotting libraries\n",
    "import numpy as np\n",
    "# Print to four digits of precision\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import numpy.linalg as npl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad32bf9",
   "metadata": {},
   "source": [
    "These exercises are to practice thinking about how the regression estimation\n",
    "works, and the relationship of correlation and regression.\n",
    "\n",
    "To give us some concrete data to play with, here are another couple of samples\n",
    "of the “psychopathy” and “clamminess” scores, of the same type that we saw in\n",
    "the [introduction to the general linear\n",
    "model](https://textbook.nipraxis.org/glm_intro.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: The data, that we are trying to model.\n",
    "psychopathy = np.array([ 11.914,   4.289,  10.825,  14.987,\n",
    "                         7.572,   5.447,   17.332,  12.105,\n",
    "                         13.297,  10.635,  21.777,  20.715])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76863115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: The regressor that we will use to model the data.\n",
    "clammy = np.array([ 0.422,  0.406,  0.061,  0.962,  4.715,\n",
    "                    1.398,  1.952,  5.095, 8.092,  5.685,\n",
    "                    5.167,  7.257])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c3a78",
   "metadata": {},
   "source": [
    "$\\newcommand{\\yvec}{\\vec{y}} \\newcommand{\\xvec}{\\vec{x}} \\newcommand{\\evec}{\\vec{\\varepsilon}}$\n",
    "\n",
    "Our simple linear model can be expressed by:\n",
    "\n",
    "$$\n",
    "y_i = c + bx_i + e_i`\n",
    "$$\n",
    "\n",
    "In vector notation:\n",
    "\n",
    "$$\n",
    "\\yvec = c + b \\xvec + \\evec\n",
    "$$\n",
    "\n",
    "$\\yvec$ is the vector of values $[y_1, y_2, ... y_n]$ we want to explain\n",
    "(psychopathy), $\\xvec$ is the vector of values $[x_1, x_2, ... x_n]$ containing\n",
    "our explanatory variable (clammy), and $\\evec$ is the vector of remaining data\n",
    "unexplained by $c + b \\xvec$.\n",
    "\n",
    "$\\newcommand{Xmat}{\\boldsymbol X} \\newcommand{\\bvec}{\\vec{\\beta}}$\n",
    "\n",
    "The same model can also be expressed using a design *matrix* $\\Xmat$:\n",
    "\n",
    "$$\n",
    "\\yvec = \\Xmat \\bvec + \\evec\n",
    "$$\n",
    "\n",
    "where $\\Xmat$ has two columns, the first being a vector of $n$ ones, and the\n",
    "second being $\\xvec$. $\\bvec$ is a column vector containing two values, $[c,\n",
    "b]$ that are, respectively, the intercept and slope of the fitted line.\n",
    "\n",
    "Now define the *mean* of $\\vec{x}$ as:\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    "$$\n",
    "\n",
    "$\\sum_{i=1}^n x_i$ means the sum (written as $\\sum$ - the Greek capital S) of all the numbers $x_1, x_2, ..., x_n$ - in other words, $x_1 + x_2 + ... + x_n$.\n",
    "\n",
    "Define two new vectors, $\\vec{x^c}, \\vec{y^c}$ that contain the values in\n",
    "$\\vec{x}, \\vec{y}$ with their respective means subtracted:\n",
    "\n",
    "$$\n",
    "\\vec{x^c} = [x_1 - \\bar{x}, x_2 - \\bar{x}, ... , x_n - \\bar{x}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{y^c} = [y_1 - \\bar{y}, y_2 - \\bar{y}, ... , y_n - \\bar{y}]\n",
    "$$\n",
    "\n",
    "We found in [introduction to the general linear\n",
    "model](https://textbook.nipraxis.org/glm_intro.html) that, for the\n",
    "case of a [full-rank](https://textbook.nipraxis.org) matrix $\\Xmat$, the least\n",
    "squares estimate for $\\bvec$ is given by:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\bhat}{\\hat{\\bvec}} \\newcommand{\\yhat}{\\hat{\\yvec}}\n",
    "\\bhat = (\\Xmat^T \\Xmat)^{-1} \\Xmat^T \\yvec\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb59b6e",
   "metadata": {},
   "source": [
    "## On vector lengths\n",
    "\n",
    "In what follows, we will refer to the idea of the *vector length* of a vector.\n",
    "This is different from the number of values in a vector, often written as $n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ff605",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(clammy)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f946565",
   "metadata": {},
   "source": [
    "In contrast *vector length* is a mathematical property of the vector *values*.\n",
    "See [vectors and dot\n",
    "products](http://matthew-brett.github.io/teaching/on_vectors.html) for the\n",
    "mathematical background.  In summary, vector length is a generalization of\n",
    "Pythagoras' theorem to more than two dimensions, and is defined as the square\n",
    "root of the sum of the squared vector values.  For example, the vector length\n",
    "of `clammy` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(clammy ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60387d13",
   "metadata": {},
   "source": [
    "Now consider a vector of values for which the mean value is 0.   We can create\n",
    "such a vector by subtracting the mean from the vector values, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2271db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = clammy - np.mean(clammy)\n",
    "# The mean is (near as the computer can calculate) 0\n",
    "np.isclose(np.mean(x_1), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a7e9a",
   "metadata": {},
   "source": [
    "The length of this vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eba2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_len = np.sqrt(np.sum(x_1 ** 2))\n",
    "x_1_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e0197",
   "metadata": {},
   "source": [
    "Here is the *standard deviation* of this vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d13d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_std = np.std(x_1)\n",
    "x_1_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61651bbd",
   "metadata": {},
   "source": [
    "Remember that, in general, the standard devation of a vector $\\vec{x}$ is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clammy  # An example vector x\n",
    "np.sqrt(np.mean((x - np.mean(x)) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091dfa9",
   "metadata": {},
   "source": [
    "Mathematically, the standard deviation for any vector $\\vec{x}$ is:\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62bd1c",
   "metadata": {},
   "source": [
    "Thinking about the calculation of the standard deviation, the calculation of the length, and the mean $\\bar{x}$ in this case, how would you recalculate the standard deviation *from the length*?\n",
    "\n",
    "You can assume the situation we have here, the sum (and mean) of the vector is 0.  Written mathematically:\n",
    "\n",
    "$$\n",
    "\\bar{\\vec{x_1}} = \\frac{1}{n} \\sum_{i=1}^n x_{1_i} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12336882",
   "metadata": {},
   "source": [
    "You may well need a sheet of paper to work out how to do this, with some\n",
    "algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a86c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "std_recalculated = ... x_1_len ...\n",
    "# Show the result\n",
    "std_recalculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d5771",
   "metadata": {},
   "source": [
    "Conversely, calculate the vector length from the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ca4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlen_recalculated = ...\n",
    "# Show the result\n",
    "vlen_recalculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a6f5c",
   "metadata": {},
   "source": [
    "## On dot products\n",
    "\n",
    "The *dot product* is the sum of the values in a vector that results from\n",
    "multiplying the two vectors together, elementwise.\n",
    "\n",
    "For example, to calculate the dot product of `psychopathy` and `clammy`, we\n",
    "first multiply the two vectors together, elementwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplied = clammy * psychopathy\n",
    "multiplied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89554c",
   "metadata": {},
   "source": [
    "The dot product is the sum of the values in `multiplied`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(multiplied)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776c0f5",
   "metadata": {},
   "source": [
    "And in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, y):\n",
    "    return np.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34912b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product(clammy, psychopathy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a72e21",
   "metadata": {},
   "source": [
    "Numpy also has a short-cut for the dot-product operation, because it is so\n",
    "common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(clammy, psychopathy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13009b",
   "metadata": {},
   "source": [
    "In fact, this is what you get when using the `@` operator in Numpy, called the\n",
    "*matrix multiplication* operator, when applied to two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clammy @ psychopathy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11c0ec",
   "metadata": {},
   "source": [
    "Have a look at the definitions of *vector length* and the dot product.  How\n",
    "would you calculate the vector length from the dot product of the vector with\n",
    "itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Recalculate the vector length using the dot product of the vector with itself\n",
    "c_dot_c = clammy @ clammy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2752e2",
   "metadata": {},
   "source": [
    "## Correlation coefficient and regression\n",
    "\n",
    "Create the $\\Xmat$ matrix from a vector of ones and the vector of `clammy`\n",
    "scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Create X design matrix from column of ones and clammy vector\n",
    "X = ...\n",
    "# Show the result.\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48824fc7",
   "metadata": {},
   "source": [
    "Are the columns of `X` orthogonal to each other?\n",
    "\n",
    "Two *vectors* are defined as being orthogonal to each other if the *dot\n",
    "product* of the two vectors is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Are the two columns of X orthogonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e75db5",
   "metadata": {},
   "source": [
    "We will now calculate the pseudoinverse.\n",
    "\n",
    "First we calculate $\\Xmat^T \\Xmat$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1489a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX = X.T @  X\n",
    "XtX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a66596",
   "metadata": {},
   "source": [
    "*For extra points* : does this matrix help us with the question as to whether\n",
    "the columns are orthogonal?  How?\n",
    "\n",
    "Calculated the matrix inverse of $\\Xmat^T \\Xmat$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Matrix inverse of X.T @ X\n",
    "iXtX = ...\n",
    "# Show the result\n",
    "iXtX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c72a3",
   "metadata": {},
   "source": [
    "If you can calculate the inverse without error, that means that $\\Xmat^T \\Xmat$\n",
    "is *invertible*.\n",
    "\n",
    "Calculate $(\\Xmat^T \\Xmat)^{-1} \\Xmat^T$ (the pseudoinverse in the invertible\n",
    "case).  What shape is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c593e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Calculate (X.T X)^-1 X.T (the pseudoinverse)\n",
    "piX = ...\n",
    "# Show the shape\n",
    "piX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862775e1",
   "metadata": {},
   "source": [
    "Calculate the least squares fit value for $\\bvec$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Calculate least squares fit for beta vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945dac8",
   "metadata": {},
   "source": [
    "Calculate the fitted values $c + b \\xvec$, and the residuals $\\evec$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157343e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Calculate the fitted values and residuals\n",
    "fitted = ...\n",
    "#-- residuals = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13541a",
   "metadata": {},
   "source": [
    "Confirm that the mean of the residuals is close to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c14169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- mean of residuals near zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9acd5",
   "metadata": {},
   "source": [
    "Confirm that residuals are orthogonal to both columns of the design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed911bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Show residuals orthogonal to both columns of design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e0e85f",
   "metadata": {},
   "source": [
    "We will now modify the design to see what happens to the parameters and the\n",
    "fitted values.\n",
    "\n",
    "We build the new design by leaving the first columns the same (a column of\n",
    "ones).   Then we change the second column (the `clammy` values) so that it is\n",
    "*orthogonal to* the first.  We can do that by subtracting the mean from the\n",
    "`clammy` vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = clammy - np.mean(clammy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b097ede",
   "metadata": {},
   "source": [
    "Confirm that `x_1` is orthogonal to the column of ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Show x_1 orthogonal to a column of ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9725a980",
   "metadata": {},
   "source": [
    "Compile the column of ones and the new regressor into an `n` by 2 design matrix\n",
    "`X_o`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_o = ...\n",
    "# Show the result\n",
    "X_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d756a1",
   "metadata": {},
   "source": [
    "Here is the matrix that we will invert to make the pseudoinverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bedcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX_o = X_o.T @ X_o\n",
    "XtX_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fe464",
   "metadata": {},
   "source": [
    "Look at the diagonal values of the matrix `X_o.T @ X_o`.  What is the\n",
    "relationship of these values to the *vector lengths* of the vectors in the\n",
    "first and second columns of `X_o`?\n",
    "\n",
    "Find the new value for $(\\Xmat^T \\Xmat)^{-1}$ – the inverse of `X_o.T @ X_o`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3934ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "iXtX_o = ...\n",
    "# Show the result\n",
    "iXtX_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6dd427",
   "metadata": {},
   "source": [
    "What is the relationship of the values in the diagonal of the inverse matrix to\n",
    "the lengths of the vectors in the first and second columns of `X_o`?\n",
    "\n",
    "*Hint*: $A^{-1} \\cdot A = I$; if $A$ has all zeros off the diagonal, what must\n",
    "$A^{-1}$ be for this to be true?\n",
    "\n",
    "Make a new data vector `y_c` by subtracting the mean from the psychopathy\n",
    "vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634cac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Make mean-centered version of psychopathy vector\n",
    "y_c = ...\n",
    "# Show the result\n",
    "y_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe68a4",
   "metadata": {},
   "source": [
    "Calculate a new `B_o` parameter vector for the least-squares fit of `X_o`\n",
    "to `y_c`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f93373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Calculate fit of X_o to y_c\n",
    "B_o = ...\n",
    "# Show the result\n",
    "B_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29264b30",
   "metadata": {},
   "source": [
    "The first parameter has changed compared to your previous estimate.  Can you\n",
    "explain why it has this new value by considering the values of $(\\Xmat^T\n",
    "\\Xmat)^{-1} \\Xmat^T \\yvec$?\n",
    "\n",
    "Calculate the correlation coefficient between `y_c` and the second column of\n",
    "`X_o`.  In case you want to play it that way, here's a function to calculate\n",
    "z-scores (standard scores), that you could use to calculate the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scores(v):\n",
    "    return (v - np.mean(v)) / np.std(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Correlation coefficient of the second column of X_o and y_c\n",
    "r_xy = ...\n",
    "# Show the result\n",
    "r_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37bfed",
   "metadata": {},
   "source": [
    "Next we explore the relationship between this correlation coefficient and `x_1`\n",
    "— the second column of the design matrix.\n",
    "\n",
    "First - consider the calculation that gave us the value for the slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regression slope.\n",
    "b = B_o[1]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb2e7b",
   "metadata": {},
   "source": [
    "We got this value via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b18977",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_o = npl.inv(X_o.T @ X_o) @ X_o.T @ y_c\n",
    "B_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f6ab6",
   "metadata": {},
   "source": [
    "We can break this calculation up into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First part.\n",
    "iXtX_o = npl.inv(X_o.T @ X_o)\n",
    "# Second part\n",
    "XtY_o = X_o.T @ y_c\n",
    "# Result (B_o)\n",
    "iXtX_o @ XtY_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5aefd8",
   "metadata": {},
   "source": [
    "Consider the second part of the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc72b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtY_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c57d04",
   "metadata": {},
   "source": [
    "This has two values:\n",
    "\n",
    "* `B_o[0]`: the dot product of the vector of ones with `y_c`\n",
    "* `B_o[1]`: the dot product of `x_1` with `y_c`\n",
    "\n",
    "Now consider the first part of the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "iXtX_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067f901",
   "metadata": {},
   "source": [
    "Remember, this is just the inverse of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX_o = X_o.T @ X_o\n",
    "XtX_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b29826",
   "metadata": {},
   "source": [
    "Matrix multiplication (`@`) takes the dot products of each left row with each\n",
    "right column.  As you may have noticed above, this means the elements on the\n",
    "diagonal are just the vector lengths of each column.  Because the columns are\n",
    "orthogonal, the off-diagonal elements are all 0.\n",
    "\n",
    "The [inverse of a diagonal matrix](https://textbook.nipraxis.org/diag_inverse)\n",
    "is another diagonal matrix where the diagonal elements are given by the\n",
    "reciprocals of the diagonal elements in the original array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c737acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First diagonal element', 1 / XtX_o[0, 0])\n",
    "print('Second diagonal element', 1 / XtX_o[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac569e0",
   "metadata": {},
   "source": [
    "Remember `x_1` is the second column of `X_o`.\n",
    "\n",
    "Now consider the whole calculation that leads up to `B_o`.  Reproduce the\n",
    "calculation of `B_o[1]`, without using matrix multiplication, and given:\n",
    "\n",
    "* the vector length of `x_1`\n",
    "* the dot product of `x_1` and `y_c`\n",
    "\n",
    "Here is the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_len = np.sqrt(x_1 @ x_1)\n",
    "x_1_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45caf0",
   "metadata": {},
   "source": [
    "Here's the dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dot_y = x_1 @ y_c\n",
    "x_dot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c731b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_reproduced = ...\n",
    "# Show the result\n",
    "b_reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e7827",
   "metadata": {},
   "source": [
    "Now we return to the correlation coefficient.\n",
    "\n",
    "Remember this is given by first subtracting the mean from each vector, then\n",
    "multiplying the resulting mean-centered vectors, to give the elementwise\n",
    "product, then taking the mean of the elementwise product.\n",
    "\n",
    "Remember that `x_1` and `y_c` already have mean zero.\n",
    "\n",
    "Consider the calculation of the correlation coefficient, and that of the dot\n",
    "product `x_dot_y` above.\n",
    "\n",
    "Reconstruct `x_dot_y` above from the correlation coefficient, `n`,\n",
    "`np.std(y_c)` and `np.std(x_1)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826cc05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y_c_std = np.std(y_c)\n",
    "x_dot_y_reconstructed =\n",
    "# Show the result\n",
    "x_dot_y_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a79a06",
   "metadata": {},
   "source": [
    "Remember the relationships you found above:\n",
    "\n",
    "* Between the standard deviation and the vector length.\n",
    "* Between the dot product of two zero-mean vectors and the correlation.\n",
    "\n",
    "See if you can use a reworking of your formula above to reconstruct `B_o[1]`\n",
    "with a calculation using only:\n",
    "\n",
    "* `r_xy` (the correlation)\n",
    "* `x_1_std`\n",
    "* `y_c_std`\n",
    "* `n` (if you need it).\n",
    "\n",
    "Try simplifying the calculation as far as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_reproduced_again = ...\n",
    "# Show the result\n",
    "b_reproduced_again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc76d4",
   "metadata": {},
   "source": [
    "Did you get the same calculation as you saw in [on\n",
    "regression](https://textbook.nipraxis.org/on_regression)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9884eeb",
   "metadata": {},
   "source": [
    "## Different models, different parameters\n",
    "\n",
    "Now try calculating $\\bvec$ fitting the `X_o` design to the original\n",
    "psychopathy data (not the mean-centered version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4842b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Fit X_o to psychopathy data\n",
    "B_o = ...\n",
    "# Show the result\n",
    "B_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7ff40",
   "metadata": {},
   "source": [
    "Compare the first value in the new `B_o` parameter vector with the mean of\n",
    "the `psychopathy` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cca99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(psychopathy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09f216",
   "metadata": {},
   "source": [
    "Can you explain the relationship?\n",
    "\n",
    "For extra points, can you explain why the second value in `B_o` did not\n",
    "change when we estimated for `psychopathy` rather than the mean-centered\n",
    "version `y_c`?  Hint: remember $(\\vec{a} + \\vec{b}) \\cdot \\vec{c} = \\vec{a}\n",
    "\\cdot \\vec{c} + \\vec{b} \\cdot \\vec{c}$.\n",
    "\n",
    "Calculate the fitted values for the `X_o` model, and compare them to the\n",
    "fitted values for the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df814686",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_X_o = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3d11e",
   "metadata": {},
   "source": [
    "For even more extra points, explain the relationship between the fitted values\n",
    "for the original model and those for the new model, where the clammy regressor\n",
    "is mean centered."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.15.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
