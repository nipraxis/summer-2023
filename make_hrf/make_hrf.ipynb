{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7be14d3",
   "metadata": {},
   "source": [
    "# Make your own hemodynamic response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import array and plotting libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Print arrays to 4 decimal places\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Nibabel and course libraries.\n",
    "import nibabel as nib\n",
    "import nipraxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf36d49",
   "metadata": {},
   "source": [
    "The file `mt_hrf_estimates.txt` contains the estimated FMRI signal from voxels\n",
    "in the MT motion area at 0, 2, 4, …, 28 seconds after a brief moving visual\n",
    "stimulus (see:\n",
    "[http://nipy.org/nitime/examples/event_related_fmri.html](http://nipy.org/nitime/examples/event_related_fmri.html)).\n",
    "\n",
    "Here are the first four rows. The numbers are in exponential floating\n",
    "point format:\n",
    "\n",
    "```\n",
    "1.394086932967517900e-01\n",
    "3.938585701431884800e-01\n",
    "5.012927230566770476e-01\n",
    "5.676763716149294536e-01\n",
    "```\n",
    "\n",
    "Read the values from the file into an array `mt_hrf_estimates`. Make a new\n",
    "array `mt_hrf_times` with the times of acquisition (0, 2, …). Plot them\n",
    "together to see the HRF estimate at these times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Load the estimated values from the text file into an array\n",
    "#- Make an array of corresponding times\n",
    "mt_hrf_estimates = ...\n",
    "mt_hrf_times = ...\n",
    "# Plot signal by time\n",
    "plt.plot(mt_hrf_times, mt_hrf_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcfe40",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "assert len(mt_hrf_times) == len(mt_hrf_estimates)\n",
    "assert np.all(mt_hrf_times[:3] == [0, 2, 4])\n",
    "assert mt_hrf_times[-1] == 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642edc5a",
   "metadata": {},
   "source": [
    "We want to make a *hemodynamic response function* that matches this shape.\n",
    "\n",
    "Our function will accept an array that gives the times we want to calculate\n",
    "the HRF for, and returns the values of the HRF for those times. We will assume\n",
    "that the true HRF starts at zero, and gets to zero sometime around 30 seconds.\n",
    "\n",
    "Like SPM, I’m going to try using the sum of two [gamma\n",
    "distribution](https://en.wikipedia.org/wiki/Gamma_distribution)\n",
    "probability density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: import the gamma density function\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd986475",
   "metadata": {},
   "source": [
    "Here’s my first shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: my attempt - you can do better than this\n",
    "def not_great_hrf(times):\n",
    "    \"\"\" Return values for HRF at given times \"\"\"\n",
    "    # Gamma pdf for the peak\n",
    "    peak_values = gamma.pdf(times, 6)\n",
    "    # Gamma pdf for the undershoot\n",
    "    undershoot_values = gamma.pdf(times, 12)\n",
    "    # Combine them\n",
    "    values = peak_values - 0.35 * undershoot_values\n",
    "    # Scale max to 0.6\n",
    "    return values / np.max(values) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332704b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: plot the data against my estimate\n",
    "plt.plot(mt_hrf_times, not_great_hrf(mt_hrf_times), label='not_great_hrf')\n",
    "plt.plot(mt_hrf_times, mt_hrf_estimates, label='mt_hrf_estimates')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430d05f",
   "metadata": {},
   "source": [
    "Now see if you can make a better function by playing with the Gamma\n",
    "distribution PDF parameter, and the mix of the two gamma distribution\n",
    "functions. Call your function `mt_hrf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af501d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Your \"mt_hrf\" function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Plot your function against the mt_hrf_estimates data to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd3450",
   "metadata": {},
   "source": [
    "For extra points - other than looking at these plots, how would you\n",
    "convince me your function is better than mine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Evidence that your function is better than mine?\n",
    "#- Your code below, to persuade me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c392d65",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "We are going to be analyzing the data for the 4D image\n",
    "`ds114_sub009_t2r1.nii` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68898061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data file.\n",
    "data_fname = nipraxis.fetch_file('ds114_sub009_t2r1.nii')\n",
    "# Show the file name of the fetched data.\n",
    "img = nib.load(data_fname)\n",
    "# Load data, drop first (bad) volume.\n",
    "data = img.get_fdata()[..., 1:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c91823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, load the condition file\n",
    "from nipraxis.stimuli import events2neural\n",
    "\n",
    "cond_fname = nipraxis.fetch_file('ds114_sub009_t2r1_cond.txt')\n",
    "TR = 2.5  # time between volumes\n",
    "n_trs = img.shape[-1]  # The original number of TRs\n",
    "neural_prediction = events2neural(cond_fname, TR, n_trs)\n",
    "# Drop value corresponding to first bad volume, dropped above.\n",
    "neural_prediction = neural_prediction[1:]\n",
    "plt.plot(neural_prediction)\n",
    "plt.ylim(0, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e9184",
   "metadata": {},
   "source": [
    "For now, we’re going to play with data for a single voxel.\n",
    "\n",
    "In the *First go at brain activation* exercise, we subtracted the rest scans\n",
    "from the task scans, something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: subtracting rest from task scans\n",
    "task_scans = data[..., neural_prediction == 1]\n",
    "rest_scans = data[..., neural_prediction == 0]\n",
    "difference = np.mean(task_scans, axis=-1) - np.mean(rest_scans, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: showing slice 14 from the difference image\n",
    "plt.imshow(difference[:, :, 14], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6658b2b",
   "metadata": {},
   "source": [
    "It looks like there’s a voxel that is greater for activation than rest at\n",
    "about (i, j, k) == (45, 43, 14).\n",
    "\n",
    "Get and plot the values for this voxel position, for every remaining volume in\n",
    "the 4D data. You can do it with a loop, but slicing is much nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Get the values for (i, j, k) = (45, 43, 14) and every volume.\n",
    "voxel_values = ...\n",
    "# Plot the values (voxel time course).\n",
    "plt.plot(voxel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06792d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(voxel_values) == 172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3f9d3",
   "metadata": {},
   "source": [
    "Correlate the predicted neural time series with the voxel time course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb483d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Correlation of predicted neural time course with voxel signal time\n",
    "#- course\n",
    "correlation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d565e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be scalar (single value).  Did you select the value\n",
    "# from the correlation array?\n",
    "assert correlation.size == 1\n",
    "assert np.round(correlation, 3) == 0.312"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af064ca",
   "metadata": {},
   "source": [
    "Now we will do a predicted hemodynamic time course using convolution.\n",
    "\n",
    "Next we need to get the HRF vector to convolve with.\n",
    "\n",
    "Remember we have defined the HRF as a function of time, not TRs.\n",
    "\n",
    "For our convolution, we need to *sample* the HRF at times corresponding the\n",
    "start of the TRs.\n",
    "\n",
    "So, we need to sample at times (0, 2.5, …)\n",
    "\n",
    "Make a vector of times at which to sample the HRF. We want to sample every TR\n",
    "up until (but not including) somewhere near 35 seconds (where the HRF should\n",
    "have got close to zero again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172fc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Make a vector of times at which to sample the HRF\n",
    "hrf_times = ...\n",
    "# Show the result\n",
    "hrf_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(hrf_times[:4], [0, 2.5, 5, 7.5])\n",
    "assert np.allclose(hrf_times[-2:], [30.0, 32.5])\n",
    "assert len(hrf_times) == 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99582276",
   "metadata": {},
   "source": [
    "Sample your `mt_hrf` HRF function at these times and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Sample HRF at given times\n",
    "hrf_signal = ...\n",
    "#- Plot HRF samples against times\n",
    "plt.plot(hrf_times, hrf_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff921e",
   "metadata": {},
   "source": [
    "Convolve the predicted neural time course with the HRF samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a56dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Convolve predicted neural time course with HRF samples\n",
    "hemodynamic_prediction = ...\n",
    "# Show the first 10 values in the result\n",
    "hemodynamic_prediction[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e58544",
   "metadata": {},
   "source": [
    "The default output of convolve is longer than the input neural prediction\n",
    "vector, by the length of the convolving vector (the HRF samples) minus 1.\n",
    "Knock these last values off the result of the convolution to get a vector the\n",
    "same length as the neural prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Remove extra tail of values put there by the convolution\n",
    "hemo_pred_short = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146c425",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "assert len(hemo_pred_short) == len(voxel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26a847",
   "metadata": {},
   "source": [
    "Plot the convolved neural prediction, and then, on the same plot, plot the\n",
    "unconvolved neural prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeeca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Plot convolved neural prediction and unconvolved neural prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3513d8",
   "metadata": {},
   "source": [
    "Does the new convolved time course correlate better with the voxel time\n",
    "course?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Correlation of the convolved time course with voxel time course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045e1c4",
   "metadata": {},
   "source": [
    "Plot the hemodynamic prediction against the actual signal (voxel values).  Investigate the `plt.` namespace for a useful function to do a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb30e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Scatterplot the hemodynamic prediction against the signal"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.13.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
