{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45140366",
   "metadata": {},
   "source": [
    "# Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52852c",
   "metadata": {},
   "source": [
    "## Introduction and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4177f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:18.998484Z",
     "iopub.status.busy": "2022-05-26T14:48:18.997722Z",
     "iopub.status.idle": "2022-05-26T14:48:19.267369Z",
     "shell.execute_reply": "2022-05-26T14:48:19.267759Z"
    }
   },
   "outputs": [],
   "source": [
    "#: Import numerical and plotting libraries\n",
    "import numpy as np\n",
    "# Print to four digits of precision\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e367cf",
   "metadata": {},
   "source": [
    "This exercise returns to the psychopathy of students from Berkeley and MIT.  It\n",
    "continues from the `on_dummies` exercise.  Make sure you have done that\n",
    "exercise before doing this one.\n",
    "\n",
    "Here are the psychopathy questionnaire scores from another set of 5 students\n",
    "from Berkeley and MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62875e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.272971Z",
     "iopub.status.busy": "2022-05-26T14:48:19.272360Z",
     "iopub.status.idle": "2022-05-26T14:48:19.274413Z",
     "shell.execute_reply": "2022-05-26T14:48:19.274830Z"
    }
   },
   "outputs": [],
   "source": [
    "ucb_psycho = np.array([2.9277, 9.7348, 12.1932, 12.2576, 5.4834])\n",
    "n_ucb = len(ucb_psycho)\n",
    "mit_psycho = np.array([7.2937, 11.1465, 13.5204, 15.053, 12.6863])\n",
    "n_mit = len(mit_psycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a55e3",
   "metadata": {},
   "source": [
    "$\\newcommand{\\yvec}{\\vec{y}}$\n",
    "\n",
    "The `psychopathy` values will be our `y` vector $\\yvec$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33aa8ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.280340Z",
     "iopub.status.busy": "2022-05-26T14:48:19.279676Z",
     "iopub.status.idle": "2022-05-26T14:48:19.282773Z",
     "shell.execute_reply": "2022-05-26T14:48:19.283191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Give name y to psychopathy, for reading convenience.\n",
    "y = np.concatenate([ucb_psycho, mit_psycho])\n",
    "# Call the number of observations \"n\"\n",
    "n = len(y)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372b7c6",
   "metadata": {},
   "source": [
    "We  use the general linear model to do a two-level (UCB, MIT) single factor\n",
    "(college) analysis of variance on these data.\n",
    "\n",
    "Our model is that the Berkeley student data are drawn from some distribution\n",
    "with a mean value that is characteristic for Berkeley: $y_i = \\mu_{Berkeley} +\n",
    "e_i$ where $i$ corresponds to a student from Berkeley.  There is also a\n",
    "characteristic but possibly different mean value for MIT: $\\mu_{MIT}$:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\xvec}{\\vec{x}}\n",
    "\\newcommand{\\evec}{\\vec{\\varepsilon}}\n",
    "\\newcommand{\\Xmat}{\\boldsymbol X}\n",
    "\\newcommand{\\bvec}{\\vec{\\beta}}\n",
    "\\newcommand{\\bhat}{\\hat{\\bvec}}\n",
    "\\newcommand{\\yhat}{\\hat{\\yvec}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_i = \\mu_{Berkeley} + e_i  \\space\\mbox{if}\\space 1 \\le i \\le 5 \\\\\n",
    "y_i = \\mu_{MIT} + e_i \\space\\mbox{if}\\space 6 \\le i \\le 10\n",
    "$$\n",
    "\n",
    "Here is the design matrix for this ANOVA, with dummy variables corresponding to\n",
    "the UCB and MIT student groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5cabde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.288045Z",
     "iopub.status.busy": "2022-05-26T14:48:19.287338Z",
     "iopub.status.idle": "2022-05-26T14:48:19.290098Z",
     "shell.execute_reply": "2022-05-26T14:48:19.290515Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Create design matrix for UCB / MIT ANOVA\n",
    "X = np.zeros((n, 2))\n",
    "X[:n_ucb, 0] = 1  # UCB indicator\n",
    "X[n_ucb:, 1] = 1  # MIT indicator\n",
    "# Show the result\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1c5471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.294290Z",
     "iopub.status.busy": "2022-05-26T14:48:19.293710Z",
     "iopub.status.idle": "2022-05-26T14:48:19.295601Z",
     "shell.execute_reply": "2022-05-26T14:48:19.296018Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "assert X.shape == (n, 2)\n",
    "assert np.all(np.sum(X, axis=0) == [n_ucb, n_mit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26f9a0",
   "metadata": {},
   "source": [
    "The betas are given by:\n",
    "\n",
    "$$\n",
    "\\bhat = (\\Xmat^T \\Xmat)^{-1}\\Xmat^T \\yvec\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0669bce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.300239Z",
     "iopub.status.busy": "2022-05-26T14:48:19.299577Z",
     "iopub.status.idle": "2022-05-26T14:48:19.302669Z",
     "shell.execute_reply": "2022-05-26T14:48:19.303105Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate transpose of design matrix multiplied by data, and therefore\n",
    "#- calculate beta vector\n",
    "B = npl.inv(X.T @ X) @ X.T @ y\n",
    "# Show the result\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6772da90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.307836Z",
     "iopub.status.busy": "2022-05-26T14:48:19.307145Z",
     "iopub.status.idle": "2022-05-26T14:48:19.308985Z",
     "shell.execute_reply": "2022-05-26T14:48:19.309446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the result is as expected, the means of each group.\n",
    "assert B.shape == (2,)\n",
    "assert np.allclose(B, [np.mean(y[:n_ucb]), np.mean(y[n_ucb:])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bb425",
   "metadata": {},
   "source": [
    "## Hypothesis testing with contrasts\n",
    "\n",
    "Remember the student’s t statistic from the general linear model :\n",
    "\n",
    "$$\n",
    "\\newcommand{\\cvec}{\\vec{c}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = \\frac{\\cvec^T \\bhat}\n",
    "{\\sqrt{\\hat{\\sigma}^2 \\cvec^T (\\Xmat^T \\Xmat)^+ \\cvec}}\n",
    "$$\n",
    "\n",
    "Let’s consider the top half of the t statistic, $c^T \\bhat$.\n",
    "\n",
    "Our hypothesis is that the mean psychopathy score for MIT students,\n",
    "$\\mu_{MIT}$, is higher than the mean psychopathy score for Berkeley students,\n",
    "$\\mu_{Berkeley}$.  What contrast vector $\\cvec$ do we need to apply to $\\bhat$\n",
    "to express the difference between these means?  Apply this contrast vector to\n",
    "$\\bhat$ to get the top half of the t statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3271af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.313767Z",
     "iopub.status.busy": "2022-05-26T14:48:19.313103Z",
     "iopub.status.idle": "2022-05-26T14:48:19.315876Z",
     "shell.execute_reply": "2022-05-26T14:48:19.316426Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Contrast vector to express difference between UCB and MIT\n",
    "#- Resulting value will be high and positive when MIT students have\n",
    "#- higher psychopathy scores than UCB students\n",
    "c = np.array([-1, 1])\n",
    "top_of_t = c @ B\n",
    "# Show the result\n",
    "top_of_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adde025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.320430Z",
     "iopub.status.busy": "2022-05-26T14:48:19.319773Z",
     "iopub.status.idle": "2022-05-26T14:48:19.321742Z",
     "shell.execute_reply": "2022-05-26T14:48:19.322290Z"
    }
   },
   "outputs": [],
   "source": [
    "assert top_of_t > 0, 'Oops, did you subtract the wrong value?'\n",
    "assert np.isclose(top_of_t, np.mean(mit_psycho) - np.mean(ucb_psycho))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ee17e",
   "metadata": {},
   "source": [
    "Now the bottom half of the t statistic.  Remember this is\n",
    "$\\sqrt{\\hat{\\sigma}^2 \\cvec^T (\\Xmat^T \\Xmat)^+ \\cvec}$.\n",
    "\n",
    "First we generate $\\hat{\\sigma^2}$ from the residuals of the model.\n",
    "\n",
    "Calculate the fitted values and the residuals given the $\\bhat$ that you have\n",
    "already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd9cdb23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.326543Z",
     "iopub.status.busy": "2022-05-26T14:48:19.325869Z",
     "iopub.status.idle": "2022-05-26T14:48:19.328242Z",
     "shell.execute_reply": "2022-05-26T14:48:19.328915Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the fitted and residual values\n",
    "fitted = X @ B\n",
    "residuals = y - fitted\n",
    "# Show residuals\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a53663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.332699Z",
     "iopub.status.busy": "2022-05-26T14:48:19.332042Z",
     "iopub.status.idle": "2022-05-26T14:48:19.334032Z",
     "shell.execute_reply": "2022-05-26T14:48:19.334473Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(residuals) == n\n",
    "assert np.isclose(np.mean(residuals), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85c7e0",
   "metadata": {},
   "source": [
    "**For reflection**: Notice we tested that the mean of the residuals was close-as-dammit to 0.  How did we know that would be true?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b81676",
   "metadata": {},
   "source": [
    "We want an unbiased variance estimate for $\\hat\\sigma^2$.  See the [worked\n",
    "example of GLM](https://textbook.nipraxis.org/mean_test_example.html) page and the [unbiased variance estimate](https://textbook.nipraxis.org/hypothesis_tests.html#unbiased-variance) section for\n",
    "details.\n",
    "\n",
    "The general rule is that we divide the sum of squares by $n - m$ where $m$ is\n",
    "the number of *independent* columns in the design matrix.  Specifically, $m$\n",
    "is the [matrix rank](http://matthew-brett.github.io/teaching/matrix_rank.html) of the design $\\Xmat$.  $m$ can also be called the\n",
    "*degrees of freedom of the design*.  $n - m$ is the *degrees of freedom of the\n",
    "error* (see [unbiased variance estimate](https://textbook.nipraxis.org/hypothesis_tests.html#unbiased-variance))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5580f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.339319Z",
     "iopub.status.busy": "2022-05-26T14:48:19.338613Z",
     "iopub.status.idle": "2022-05-26T14:48:19.341192Z",
     "shell.execute_reply": "2022-05-26T14:48:19.341624Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the degrees of freedom consumed by the design.\n",
    "m = npl.matrix_rank(X)\n",
    "#- Calculate the degrees of freedom of the error.\n",
    "df_error = n - m\n",
    "# Show degrees of freedom due to error.\n",
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54d196",
   "metadata": {},
   "source": [
    "Calculate the unbiased *variance* estimate $\\hat{\\sigma^2}$ by dividing the\n",
    "sums of squares of the residuals by the degrees of freedom of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1266e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.345725Z",
     "iopub.status.busy": "2022-05-26T14:48:19.345072Z",
     "iopub.status.idle": "2022-05-26T14:48:19.347598Z",
     "shell.execute_reply": "2022-05-26T14:48:19.348037Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the unbiased variance estimate\n",
    "var_hat = np.sum(residuals ** 2) / df_error\n",
    "# Show the result\n",
    "var_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3894e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.351847Z",
     "iopub.status.busy": "2022-05-26T14:48:19.351185Z",
     "iopub.status.idle": "2022-05-26T14:48:19.352994Z",
     "shell.execute_reply": "2022-05-26T14:48:19.353441Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.round(var_hat, 3) == 13.049"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79228510",
   "metadata": {},
   "source": [
    "Now the calculate second part of the t statistic denominator,  $\\cvec^T (\\Xmat^T\n",
    "\\Xmat)^+ \\cvec$. You already know that $\\Xmat^T \\Xmat$ is invertible, and you\n",
    "have its inverse above, so you can use the inverse instead of the more general\n",
    "pseudo-inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788ec5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.357954Z",
     "iopub.status.busy": "2022-05-26T14:48:19.357270Z",
     "iopub.status.idle": "2022-05-26T14:48:19.359855Z",
     "shell.execute_reply": "2022-05-26T14:48:19.360330Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate c (X.T X)^-1 c.T\n",
    "c_iXtX_ct = c @ npl.inv(X.T @ X) @ c.T\n",
    "# Show the result\n",
    "c_iXtX_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ffdc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.363998Z",
     "iopub.status.busy": "2022-05-26T14:48:19.363340Z",
     "iopub.status.idle": "2022-05-26T14:48:19.365233Z",
     "shell.execute_reply": "2022-05-26T14:48:19.365682Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(c_iXtX_ct, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c703457",
   "metadata": {},
   "source": [
    "The final deminator of the t-statistic is the square root of the estimated variance `var_hat` mutiplied by the second half you have just calculated. The t-statistic is the numerator divided by the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddbb33e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.369639Z",
     "iopub.status.busy": "2022-05-26T14:48:19.368969Z",
     "iopub.status.idle": "2022-05-26T14:48:19.371611Z",
     "shell.execute_reply": "2022-05-26T14:48:19.372125Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate t-statistic\n",
    "t_stat = top_of_t / np.sqrt(var_hat * c_iXtX_ct)\n",
    "# Show the result\n",
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c85cf687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.375959Z",
     "iopub.status.busy": "2022-05-26T14:48:19.375301Z",
     "iopub.status.idle": "2022-05-26T14:48:19.377271Z",
     "shell.execute_reply": "2022-05-26T14:48:19.377719Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.round(t_stat, 3) == 1.497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce3c51",
   "metadata": {},
   "source": [
    "How likely is a t-statistic value this positive, or more positive, if there was in fact no underlying difference between the groups ? Use the `stats` module from `scipy` to create a\n",
    "t-distribution with `df_error` (degrees of freedom of the error).  See the\n",
    "`t_stat` function in [introduction to the general linear model](https://matthew-brett.github.io/teaching/glm_intro.html) for\n",
    "inspiration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ed8707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.381618Z",
     "iopub.status.busy": "2022-05-26T14:48:19.380970Z",
     "iopub.status.idle": "2022-05-26T14:48:19.717203Z",
     "shell.execute_reply": "2022-05-26T14:48:19.717621Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Use scipy.stats to give a probability of a value as positive as the one you observe.\n",
    "import scipy.stats as sst\n",
    "tdistrib = sst.t(df_error)\n",
    "# 1 - cumulative density function (P(x <= t)\n",
    "1. - tdistrib.cdf(t_stat)\n",
    "# This is the same as the \"survival function\"\n",
    "p_val = tdistrib.sf(t_stat)\n",
    "# Show the result\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c94a2",
   "metadata": {},
   "source": [
    "Check your result against the Scipy implementation of the independent t-test.\n",
    "\n",
    "Scipy, by default, calculates the two-tailed p-value, whereas you have calculated the one-sided value.  Scipy's p value should be very close to 2 x your p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7fd47b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.722051Z",
     "iopub.status.busy": "2022-05-26T14:48:19.721389Z",
     "iopub.status.idle": "2022-05-26T14:48:19.723788Z",
     "shell.execute_reply": "2022-05-26T14:48:19.724236Z"
    }
   },
   "outputs": [],
   "source": [
    "t_test_result = sst.ttest_ind(mit_psycho, ucb_psycho)\n",
    "t_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99518f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.727908Z",
     "iopub.status.busy": "2022-05-26T14:48:19.727309Z",
     "iopub.status.idle": "2022-05-26T14:48:19.729018Z",
     "shell.execute_reply": "2022-05-26T14:48:19.729431Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(t_test_result.statistic, t_stat)\n",
    "assert np.isclose(t_test_result.pvalue, p_val * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909a6be",
   "metadata": {},
   "source": [
    "## Advanced hypothesis testing: F-tests\n",
    "\n",
    "For this part of the exercise, you might consider reading [hypothesis tests\n",
    "with the GLM](https://textbook.nipraxis.org/hypothesis_tests.html).\n",
    "\n",
    "Imagine we have also measured the clammy score for the Berkeley and MIT\n",
    "students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e904f106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T14:48:19.733122Z",
     "iopub.status.busy": "2022-05-26T14:48:19.732528Z",
     "iopub.status.idle": "2022-05-26T14:48:19.734500Z",
     "shell.execute_reply": "2022-05-26T14:48:19.734915Z"
    }
   },
   "outputs": [],
   "source": [
    "#: Clamminess of handshake for UCB and MIT students\n",
    "clammy = np.array([2.6386, 9.6094, 8.3379, 6.2871, 7.2775, 2.4787,\n",
    "                   8.6037, 12.8713, 10.4906, 5.6766])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445f70e",
   "metadata": {},
   "source": [
    "We want to test whether the clammy score is useful in explaining\n",
    "the psychopathy data, over and above the students’ college affiliation.\n",
    "\n",
    "To do this, we will use an [F test](https://textbook.nipraxis.org/hypothesis_tests.html#f-tests).\n",
    "\n",
    "An F-test compares a *full model* $\\Xmat_f$ with a *reduced model* $\\Xmat_r$.\n",
    "\n",
    "In our case, $\\Xmat_f$ is the model containing the `clammy` regressor, as\n",
    "well as the two dummy columns for the UCB and MIT group means.\n",
    "\n",
    "$\\Xmat_r$ is our original model, that only contains the dummy columns for the\n",
    "UCB and MIT group means.\n",
    "\n",
    "We define $SSR(\\Xmat_r)$ and $SSR(\\Xmat_f)$ as in [hypothesis tests](https://textbook.nipraxis.org/hypothesis_tests.html).\n",
    "These are the Sums of Squares of the Residuals of the reduced and full model\n",
    "respectively.\n",
    "\n",
    "$$\n",
    "\\bhat_r = \\Xmat_r^+ \\yvec \\\\\n",
    "\\hat\\evec_r = \\yvec - \\Xmat_r \\bhat_r \\\\\n",
    "SSR(\\Xmat_r) = \\hat\\evec_r^T \\hat\\evec_r \\\\\n",
    "\\\\\n",
    "\\bhat_f = \\Xmat_f^+ \\yvec \\\\\n",
    "\\hat\\evec_f = \\yvec - \\Xmat_f \\bhat_f \\\\\n",
    "SSR(\\Xmat_f) = \\hat\\evec_f^T \\hat\\evec_f\n",
    "$$\n",
    "\n",
    "You can calculate the F statistic for adding the `clammy` regressor, by\n",
    "using these calculations and the formula for the F-test in [F tests](https://textbook.nipraxis.org/hypothesis_tests.html#f-tests).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.13.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
